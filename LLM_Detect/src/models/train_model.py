import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
import tensorflow as tf
from tensorflow import keras
import seaborn as sns
import nltk
from nltk.corpus import stopwords
import string
from nltk.stem.snowball import SnowballStemmer
from sklearn.feature_extraction.text import CountVectorizer
snowball = SnowballStemmer(language='english')
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier as XGB
from sklearn.metrics import confusion_matrix
from sklearn.svm import SVC
import transformers
from transformers import BertTokenizer, TFBertForSequenceClassification
from numba import cuda

import os
import sys
# sys.path.append(os.path.join(os.path.dirname(__file__), '..'))


sys.path.insert(0, '../data')



current_path = os.path.dirname(os.path.abspath(__file__))
sys.path.append('/Users/tianyuliu/CodeProjects/kaggle/LLM_Detect/LLM_Detect') 

train_csv_loc = "/data/input/llm-detect-ai-generated-text/train_essays.csv"
train_csv = pd.read_csv(train_csv_loc)


prompts_csv = "/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv"
pd.read_csv(prompts_csv)

llm_gen_perc = train_csv.groupby('generated').count()['text']
print(llm_gen_perc)
plt.title("Amount of text generated by LLM vs amount of text written by children")
plt.pie(llm_gen_perc,labels=['generated by students','generated by LLM'],autopct = '%0.2f%%',shadow=True)

prompt_perc = train_csv.groupby('prompt_id').count()['generated']
print(prompt_perc)
plt.title("Prompts")
plt.pie(prompt_perc,labels=["Car-free cities","Does the electoral college work?"],autopct="%0.2f%%",shadow=True)



dataset_1_loc ='/kaggle/input/llm-mistral-7b-instruct-texts/Mistral7B_CME_v6.csv'
aug_data1 = pd.read_csv(dataset_1_loc)
aug_data1 = aug_data1[aug_data1["prompt_id"]==2]
aug_data1["prompt_id"]=aug_data1['prompt_id']-2
aug_data1



dataset_2_loc = '/kaggle/input/llm-mistral-7b-instruct-texts/Mistral7B_CME_v7.csv'
aug_data2 = pd.read_csv(dataset_2_loc)
aug_data2 = aug_data2[aug_data2["prompt_id"]==12]
aug_data2["prompt_id"]=aug_data2['prompt_id']-11
aug_data2



aug_data_mistral = pd.concat([aug_data1,aug_data2],axis=0)


aug_data_mistral = aug_data_mistral.drop(columns= ['prompt_name'])
aug_data_mistral


train_csv= train_csv.drop(columns=['id'])


final_data = pd.concat([train_csv,aug_data_mistral],axis=0)



classes = final_data.groupby('generated').count()['text']
plt.title('Class imbalance solved')
plt.pie(classes, labels=['generated by AI','not generated by AI'],colors=['skyblue','cyan'],shadow=True,autopct='%0.2f%%')



prompts_final = final_data.groupby('prompt_id').count()['generated']
print(prompts_final)
plt.title('Both prompts given equal weightage')
plt.pie(prompts_final, labels=['Car-free cities','Does the electoral college work?'],colors=['g','y'], shadow=True,autopct='%0.2f%%')


final_data['text'].index = np.arange(0,2778)

stemtext = []
para = final_data['text'].tolist()
for paragraph in para:
    char = [char for char in paragraph if char not in string.punctuation]
    word = "".join(char).split(" ")
    words = [word.lower() for word in word if word not in stopwords.words('english')]
    stemwords = [SnowballStemmer('english').stem(word) for word in words]
    stemtext.append(" ".join(stemwords))


test = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')



x_train, x_test ,y_train , y_test = train_test_split(final_data.iloc[:,0:2], final_data['generated'],test_size=0.2)
x_train['labels'] = y_train
x_test['labels'] = y_test



tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
def tokenize_data(data):
    return tokenizer(data['text'].tolist(), padding=True, truncation=True, return_tensors='tf'), data['labels'].tolist()
train_token= tokenize_data(x_train)
val_token = tokenize_data(x_test)


model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')

optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)
loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

model.compile(optimizer=optimizer, loss=loss_function, metrics=['sparse_categorical_crossentropy'])



batch_size = 8
num_epochs = 2
train_dataset = tf.data.Dataset.from_tensor_slices((
    {
        'input_ids': train_token[0]['input_ids'],
        'token_type_ids': train_token[0]['token_type_ids'],
        'attention_mask': train_token[0]['attention_mask'],
    },
    train_token[1] 
)).shuffle(1000).batch(batch_size)
val_dataset = tf.data.Dataset.from_tensor_slices((
    {
        'input_ids': val_token[0]['input_ids'],
        'token_type_ids': val_token[0]['token_type_ids'],
        'attention_mask': val_token[0]['attention_mask'],
    },
    val_token[1]  
)).batch(batch_size)
model.fit(train_dataset, epochs=num_epochs, validation_data=val_dataset)




stemtext1 = []
para1 = test['text'].tolist()
for paragraph in para1:
    char1 = [char for char in paragraph if char not in string.punctuation]
    word1 = "".join(char1).split(" ")
    words1 = [word.lower() for word in word1 if word not in stopwords.words('english')]
    stemwords1 = [SnowballStemmer('english').stem(word) for word in words1]
    stemtext1.append(" ".join(stemwords1))


test['text'] = stemtext1


def tokenize_testdata(data):
    return tokenizer(data['text'].tolist(), padding=True, truncation=True, return_tensors='tf')
test_token = tokenize_testdata(test)  


test_batch_size = 2  # or any smaller value
test_dataset = tf.data.Dataset.from_tensor_slices({
    'input_ids': test_token['input_ids'],
    'token_type_ids': test_token['token_type_ids'],
    'attention_mask': test_token['attention_mask'],
}).batch(test_batch_size)


predictions = model.predict(test_dataset)
logits = predictions.logits  
result = tf.nn.softmax(logits, axis=-1).numpy()


submit = pd.DataFrame(test['id'])
submit['generated'] = result[:,0]


submit.to_csv('submission.csv', index=False)











